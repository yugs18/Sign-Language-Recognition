{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path to dataset keypoints JSON files\n",
    "KEYPOINTS_PATH = \"../dataset/keypoints\"\n",
    "OUTPUT_DIR = \"../dataset/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir(directory_path):\n",
    "    \"\"\"Creates a directory if it does not already exist.\"\"\"\n",
    "    os.makedirs(directory_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_keypoints_with_label(keypoints_path, label):\n",
    "    \"\"\"\n",
    "    Loads keypoints for a given label, filters out invalid data, and adds the label to each entry.\n",
    "\n",
    "    Args:\n",
    "        keypoints_path (str): Path to the folder containing JSON files for keypoints.\n",
    "        label (str): The label of the data (e.g., 'A', '1').\n",
    "\n",
    "    Returns:\n",
    "        list: Cleaned list of keypoints data with the label included.\n",
    "    \"\"\"\n",
    "    label_file = os.path.join(keypoints_path, f\"{label}.json\")\n",
    "    keypoints_data = []\n",
    "\n",
    "    if not os.path.exists(label_file):\n",
    "        print(f\"JSON file not found: {label_file}\")\n",
    "        return keypoints_data\n",
    "\n",
    "    with open(label_file, 'r') as json_file:\n",
    "        data = json.load(json_file)\n",
    "\n",
    "    # Clean the data: Remove entries with all zero keypoints\n",
    "    for entry in data:\n",
    "        body_keypoints = entry[\"keypoints\"][\"body\"]\n",
    "        hand_keypoints = entry[\"keypoints\"][\"hands\"]\n",
    "\n",
    "        # Check if all keypoints are zero\n",
    "        if all(kp[\"x\"] == 0.0 and kp[\"y\"] == 0.0 and kp[\"z\"] == 0.0 for kp in body_keypoints) and all(kp[\"x\"] == 0.0 and kp[\"y\"] == 0.0 and kp[\"z\"] == 0.0 for kp in hand_keypoints):\n",
    "            continue  # Skip this entry if all keypoints are zero\n",
    "\n",
    "        keypoints_data.append({\n",
    "            \"label\": label,\n",
    "            \"image_name\": entry[\"image_name\"],\n",
    "            \"keypoints\": {\n",
    "                \"body\": body_keypoints,\n",
    "                \"hands\": hand_keypoints\n",
    "            }\n",
    "        })\n",
    "\n",
    "    return keypoints_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, train_ratio=0.8, val_ratio=0.1, test_ratio=0.1):\n",
    "    \"\"\"\n",
    "    Splits the data into train, validation, and test sets.\n",
    "\n",
    "    Args:\n",
    "        data (list): List of keypoints data.\n",
    "        train_ratio (float): Fraction of data for the train set.\n",
    "        val_ratio (float): Fraction of data for the validation set.\n",
    "        test_ratio (float): Fraction of data for the test set.\n",
    "\n",
    "    Returns:\n",
    "        tuple: train, val, test lists of keypoints data.\n",
    "    \"\"\"\n",
    "    random.shuffle(data)  # Shuffle the data\n",
    "    total = len(data)\n",
    "    \n",
    "    train_end = int(train_ratio * total)\n",
    "    val_end = train_end + int(val_ratio * total)\n",
    "\n",
    "    train_data = data[:train_end]\n",
    "    val_data = data[train_end:val_end]\n",
    "    test_data = data[val_end:]\n",
    "\n",
    "    return train_data, val_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_split_data(train_data, val_data, test_data, output_path):\n",
    "    \"\"\"\n",
    "    Saves all split data (train, val, test) into single JSON files for each split.\n",
    "\n",
    "    Args:\n",
    "        train_data (list): List of keypoints data for the training set.\n",
    "        val_data (list): List of keypoints data for the validation set.\n",
    "        test_data (list): List of keypoints data for the test set.\n",
    "        output_path (str): Path to save the split JSON files.\n",
    "    \"\"\"\n",
    "    all_splits = {\n",
    "        \"train\": train_data,\n",
    "        \"val\": val_data,\n",
    "        \"test\": test_data\n",
    "    }\n",
    "\n",
    "    for split_type, split_data in all_splits.items():\n",
    "        json_path = os.path.join(output_path, f\"{split_type}_data.json\")\n",
    "        with open(json_path, 'w') as json_file:\n",
    "            json.dump(split_data, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Create output directory\n",
    "    create_dir(OUTPUT_DIR)\n",
    "\n",
    "    # Initialize lists to store all data for train, val, and test sets\n",
    "    all_train_data = []\n",
    "    all_val_data = []\n",
    "    all_test_data = []\n",
    "\n",
    "    # Process all labels and split their data\n",
    "    labels = list(\"123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ\")\n",
    "\n",
    "    for label in labels:\n",
    "        # Load keypoints for the label and clean data\n",
    "        keypoints = load_keypoints_with_label(KEYPOINTS_PATH, label)\n",
    "        \n",
    "        if keypoints:  # If there is keypoints data for this label\n",
    "            # Split the data into train, val, and test\n",
    "            train_data, val_data, test_data = split_data(keypoints)\n",
    "\n",
    "            # Append the split data to the respective lists\n",
    "            all_train_data.extend(train_data)\n",
    "            all_val_data.extend(val_data)\n",
    "            all_test_data.extend(test_data)\n",
    "\n",
    "    # Save the final split data into separate JSON files for train, val, and test\n",
    "    save_split_data(all_train_data, all_val_data, all_test_data, OUTPUT_DIR)\n",
    "\n",
    "    print(\"Keypoints data split into train, validation, and test sets complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keypoints data split into train, validation, and test sets complete.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
