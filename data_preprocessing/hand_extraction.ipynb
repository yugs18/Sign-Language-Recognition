{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "input_dir = \"../augmented_images\"\n",
    "output_dir = \"../hand_images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels where both hands must be present\n",
    "labels_with_both_hands = list(\"ABDEFGHJKMNPQRSTWXYZ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libEGL warning: MESA-LOADER: failed to open zink: /usr/lib/dri/zink_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open zink: /usr/lib/dri/zink_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open zink: /usr/lib/dri/zink_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1738012479.575562  200014 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1738012479.632448  200022 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "# Mediapipe setup\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=True, max_num_hands=2, min_detection_confidence=0.5)\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding factor (adjust this to add more/less margin around the hand)\n",
    "PADDING = 0.1  # 10% margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process and crop images\n",
    "def process_images(input_dir, output_dir):\n",
    "    for label in os.listdir(input_dir):\n",
    "        label_path = os.path.join(input_dir, label)\n",
    "        if not os.path.isdir(label_path):\n",
    "            continue\n",
    "\n",
    "        output_label_path = os.path.join(output_dir, label)\n",
    "        os.makedirs(output_label_path, exist_ok=True)\n",
    "\n",
    "        for img_name in tqdm(os.listdir(label_path), desc=f\"Processing label {label}\"):\n",
    "            img_path = os.path.join(label_path, img_name)\n",
    "            img = cv2.imread(img_path)\n",
    "\n",
    "            if img is None:\n",
    "                continue\n",
    "\n",
    "            # Convert the image to RGB\n",
    "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Detect hand landmarks\n",
    "            result = hands.process(img_rgb)\n",
    "\n",
    "            if result.multi_hand_landmarks:\n",
    "                # Check for the required number of hands\n",
    "                num_hands = len(result.multi_hand_landmarks)\n",
    "                if label in labels_with_both_hands and num_hands < 2:\n",
    "                    continue\n",
    "\n",
    "                h, w, _ = img.shape\n",
    "\n",
    "                # Initialize variables to store the overall bounding box for all hands\n",
    "                x_min, y_min = w, h\n",
    "                x_max, y_max = 0, 0\n",
    "\n",
    "                # Update the bounding box to include all hands\n",
    "                for hand_landmarks in result.multi_hand_landmarks:\n",
    "                    x_min = min(x_min, int(min([lm.x for lm in hand_landmarks.landmark]) * w))\n",
    "                    x_max = max(x_max, int(max([lm.x for lm in hand_landmarks.landmark]) * w))\n",
    "                    y_min = min(y_min, int(min([lm.y for lm in hand_landmarks.landmark]) * h))\n",
    "                    y_max = max(y_max, int(max([lm.y for lm in hand_landmarks.landmark]) * h))\n",
    "\n",
    "                # Add padding to the bounding box\n",
    "                x_min = max(0, int(x_min - PADDING * (x_max - x_min)))\n",
    "                x_max = min(w, int(x_max + PADDING * (x_max - x_min)))\n",
    "                y_min = max(0, int(y_min - PADDING * (y_max - y_min)))\n",
    "                y_max = min(h, int(y_max + PADDING * (y_max - y_min)))\n",
    "\n",
    "                # Crop the region containing both hands\n",
    "                cropped_img = img[y_min:y_max, x_min:x_max]\n",
    "\n",
    "                # Save the cropped image\n",
    "                output_path = os.path.join(output_label_path, img_name)\n",
    "                cv2.imwrite(output_path, cropped_img)\n",
    "            else:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing label V: 100%|██████████| 5000/5000 [02:09<00:00, 38.57it/s]\n",
      "Processing label S: 100%|██████████| 5000/5000 [02:35<00:00, 32.09it/s]\n",
      "Processing label J: 100%|██████████| 5000/5000 [02:50<00:00, 29.28it/s]\n",
      "Processing label W: 100%|██████████| 5000/5000 [02:31<00:00, 32.97it/s]\n",
      "Processing label 6: 100%|██████████| 5000/5000 [02:08<00:00, 38.82it/s]\n",
      "Processing label 9: 100%|██████████| 5000/5000 [02:08<00:00, 38.80it/s]\n",
      "Processing label M: 100%|██████████| 5000/5000 [02:39<00:00, 31.26it/s]\n",
      "Processing label Q: 100%|██████████| 5000/5000 [02:52<00:00, 28.99it/s]\n",
      "Processing label K: 100%|██████████| 5000/5000 [02:51<00:00, 29.15it/s]\n",
      "Processing label E: 100%|██████████| 5000/5000 [02:52<00:00, 29.06it/s]\n",
      "Processing label R: 100%|██████████| 5000/5000 [02:36<00:00, 32.02it/s]\n",
      "Processing label X: 100%|██████████| 5000/5000 [02:50<00:00, 29.33it/s]\n",
      "Processing label D: 100%|██████████| 5000/5000 [02:50<00:00, 29.33it/s]\n",
      "Processing label F: 100%|██████████| 5000/5000 [02:41<00:00, 31.01it/s]\n",
      "Processing label O: 100%|██████████| 5000/5000 [02:08<00:00, 39.03it/s]\n",
      "Processing label 2: 100%|██████████| 5000/5000 [02:08<00:00, 38.79it/s]\n",
      "Processing label 4: 100%|██████████| 5000/5000 [02:10<00:00, 38.32it/s]\n",
      "Processing label T: 100%|██████████| 5000/5000 [02:43<00:00, 30.63it/s]\n",
      "Processing label C: 100%|██████████| 5000/5000 [02:09<00:00, 38.70it/s]\n",
      "Processing label Z: 100%|██████████| 5000/5000 [02:39<00:00, 31.31it/s]\n",
      "Processing label Y: 100%|██████████| 5000/5000 [02:45<00:00, 30.16it/s]\n",
      "Processing label L: 100%|██████████| 5000/5000 [02:14<00:00, 37.18it/s]\n",
      "Processing label A: 100%|██████████| 5000/5000 [02:45<00:00, 30.21it/s]\n",
      "Processing label N: 100%|██████████| 5000/5000 [02:44<00:00, 30.38it/s]\n",
      "Processing label 1: 100%|██████████| 5185/5185 [02:13<00:00, 38.71it/s]\n",
      "Processing label H: 100%|██████████| 5000/5000 [02:21<00:00, 35.43it/s]\n",
      "Processing label 8: 100%|██████████| 5000/5000 [02:10<00:00, 38.32it/s]\n",
      "Processing label U: 100%|██████████| 5000/5000 [02:09<00:00, 38.62it/s]\n",
      "Processing label G: 100%|██████████| 5000/5000 [02:46<00:00, 30.11it/s]\n",
      "Processing label 3: 100%|██████████| 5000/5000 [02:09<00:00, 38.61it/s]\n",
      "Processing label P: 100%|██████████| 5000/5000 [02:48<00:00, 29.62it/s]\n",
      "Processing label 7: 100%|██████████| 5000/5000 [02:08<00:00, 38.85it/s]\n",
      "Processing label B: 100%|██████████| 5000/5000 [02:54<00:00, 28.60it/s]\n",
      "Processing label 5: 100%|██████████| 5000/5000 [02:10<00:00, 38.43it/s]\n",
      "Processing label I: 100%|██████████| 5000/5000 [02:09<00:00, 38.76it/s]\n"
     ]
    }
   ],
   "source": [
    "# Run the process\n",
    "process_images(input_dir, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Release Mediapipe resources\n",
    "hands.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
